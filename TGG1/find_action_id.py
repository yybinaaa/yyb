import json
import pickle
from pathlib import Path
from tqdm import tqdm
from collections import Counter
import os

def find_action_feature_id(data_dir: Path):
    """
    é€šè¿‡æ‰«æ seq.jsonl å’Œ indexer.pkl æ¥è‡ªåŠ¨æ¨æ–­
    å“ªä¸ª feature_id å¯¹åº” action_typeã€‚
    """
    seq_file = data_dir / "seq.jsonl"
    indexer_file = data_dir / "indexer.pkl"

    if not seq_file.exists() or not indexer_file.exists():
        raise FileNotFoundError(f"è¯·ç¡®ä¿ {seq_file} å’Œ {indexer_file} å­˜åœ¨ã€‚")

    print("--- æ­¥éª¤ 1: æ‰«æ seq.jsonl ä»¥æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„ action_type re-id ---")
    
    action_type_values = set()
    with open(seq_file, 'r', encoding='utf-8') as f:
        for line in tqdm(f, desc="æ‰«æAction Types"):
            try:
                sequence = json.loads(line)
                for record in sequence:
                    # record[4] is action_type
                    action_val = record[4]
                    if action_val is not None:
                        action_type_values.add(action_val)
            except (json.JSONDecodeError, IndexError):
                continue
    
    if not action_type_values:
        print("âŒ é”™è¯¯: åœ¨ seq.jsonl ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ action_type å€¼ã€‚")
        return None

    print(f"âœ… æ‰«æå®Œæˆã€‚å‘ç°çš„ Action Type re-id å€¼: {sorted(list(action_type_values))}")
    
    print("\n--- æ­¥éª¤ 2: åŠ è½½ indexer.pkl å¹¶åå‘æŸ¥æ‰¾ç‰¹å¾ID ---")
    with open(indexer_file, 'rb') as f:
        indexer = pickle.load(f)
        
    feature_dictionaries = indexer.get('f', {})
    if not feature_dictionaries:
        print("âŒ é”™è¯¯: indexer.pkl ä¸­æ²¡æœ‰ 'f' (ç‰¹å¾) å­—æ®µã€‚")
        return None

    candidate_features = []
    print("æ­£åœ¨åŒ¹é…è¯å…¸...")
    for feature_id, value_map in feature_dictionaries.items():
        # value_map æ˜¯ä¸€ä¸ª dict, e.g., {'val_A': 1, 'val_B': 2}
        # æˆ‘ä»¬éœ€è¦æ£€æŸ¥å®ƒçš„ values()
        indexed_values_in_dict = set(value_map.values())
        
        # åˆ¤æ–­ action_type_values æ˜¯å¦æ˜¯ indexed_values_in_dict çš„å­é›†
        if action_type_values.issubset(indexed_values_in_dict):
            # è®¡ç®—åŒ¹é…åº¦ï¼šè¯å…¸ä¸­é¢å¤–å…ƒç´ çš„æ•°é‡ã€‚è¶Šå°‘è¶Šå¥½ã€‚
            extra_elements = len(indexed_values_in_dict - action_type_values)
            candidate_features.append({
                'id': feature_id,
                'match_score': extra_elements, # åˆ†æ•°è¶Šä½ï¼ŒåŒ¹é…è¶Šå¥½
                'vocab_size': len(indexed_values_in_dict)
            })
            print(f"  - å‘ç°å€™é€‰ç‰¹å¾ID: '{feature_id}' (è¯å…¸å¤§å°: {len(indexed_values_in_dict)}, é¢å¤–å…ƒç´ : {extra_elements})")

    if not candidate_features:
        print("\nâŒ æœªèƒ½æ‰¾åˆ°ä»»ä½•ç‰¹å¾çš„è¯å…¸å®Œå…¨åŒ…å«æ‰€æœ‰å‘ç°çš„ action_type å€¼ã€‚")
        print("è¿™å¯èƒ½æ„å‘³ç€ action_type æ²¡æœ‰è¢«åŒ…å«åœ¨ indexer['f'] ä¸­ï¼Œæˆ–è€…æ•°æ®æœ‰è¯¯ã€‚")
        return None

    # æŒ‰åŒ¹é…åˆ†æ•°ï¼ˆé¢å¤–å…ƒç´ æ•°é‡ï¼‰æ’åºï¼Œåˆ†æ•°è¶Šä½è¶Šé å‰
    candidate_features.sort(key=lambda x: x['match_score'])
    
    best_match = candidate_features[0]
    
    print("\n--- ç»“è®º ---")
    print(f"ğŸ‰ æœ€æœ‰å¯èƒ½çš„ Action Feature ID æ˜¯: '{best_match['id']}'")
    print(f"   - å®ƒçš„è¯å…¸å¤§å°æ˜¯ {best_match['vocab_size']}")
    print(f"   - ä¸å®é™…actionå€¼ç›¸æ¯”ï¼Œå®ƒåªå¤šäº† {best_match['match_score']} ä¸ªé¢å¤–å…ƒç´  (æœ€å°‘)ã€‚")
    print("\nè¯·å°†è¿™ä¸ªIDç”¨äºæ‚¨çš„ main_three_tower.py è„šæœ¬ä¸­ã€‚")
    
    return best_match['id']


if __name__ == '__main__':
    data_path = Path(os.environ.get('TRAIN_DATA_PATH', 'data'))
    find_action_feature_id(data_path)