import json
import pickle
from pathlib import Path
from tqdm import tqdm
import os

def restructure_provided_data(data_dir: Path):
    """
    è¯»å–å®˜æ–¹æä¾›çš„æ•°æ®æ–‡ä»¶ï¼Œå°†å…¶é‡ç»„ä¸ºæˆ‘ä»¬ä¸ºé«˜æ•ˆè®­ç»ƒè®¾è®¡çš„ç»“æ„ã€‚
    - è¯»å– item_feat_dict.json -> åˆ›å»º item_features.pkl
    - è¯»å– seq.jsonl -> æå–ç”¨æˆ·ç‰¹å¾ -> åˆ›å»º user_features.pkl
    """
    print("ğŸš€ å¼€å§‹é‡ç»„å®˜æ–¹æ•°æ®ä»¥ä¾¿é«˜æ•ˆåŠ è½½...")

    # --- å‚æ•°å®šä¹‰ ---
    # è¿™äº›ç‰¹å¾é”®åˆ—è¡¨éœ€è¦æ‚¨æ ¹æ®å®é™…æƒ…å†µç¡®è®¤
    USER_SPARSE_KEYS = ['103', '104', '105', '109'] # å‡è®¾è¿™äº›æ˜¯ç”¨æˆ·ç¨€ç–ç‰¹å¾
    USER_ARRAY_KEYS = ['205', '207'] # å‡è®¾è¿™äº›æ˜¯ç”¨æˆ·æ•°ç»„ç‰¹å¾
    MAX_ARRAY_LENGTH_K = 10 # æœ€ç»ˆæ¯ä¸ªç”¨æˆ·çš„æ•°ç»„ç‰¹å¾ï¼Œæˆ‘ä»¬é€‰æ‹© K ä¸ª

    # --- æ–‡ä»¶è·¯å¾„ ---
    user_seq_file = data_dir / "seq.jsonl"
    item_feat_file = data_dir / "item_feat_dict.json"
    if not user_seq_file.exists() or not item_feat_file.exists():
        raise FileNotFoundError(f"è¯·ç¡®ä¿ {user_seq_file} å’Œ {item_feat_file} éƒ½å­˜åœ¨ã€‚")

    # --- 1. å¤„ç†ç‰©å“ç‰¹å¾ ---
    print("\n--- æ­¥éª¤ 1: è½¬æ¢ item_feat_dict.json -> item_features.pkl ---")
    with open(item_feat_file, 'r', encoding='utf-8') as f:
        item_feat_dict = json.load(f)
    
    # å› ä¸º key å·²ç»æ˜¯ re-idï¼Œæˆ‘ä»¬åªéœ€è¦ç¡®ä¿å®ƒä»¬æ˜¯æ•´æ•°ç±»å‹
    item_features_data = {int(k): v for k, v in item_feat_dict.items()}

    with open(data_dir / 'item_features.pkl', 'wb') as f:
        pickle.dump(item_features_data, f)
    print(f"  - âœ… å·²ä¿å­˜: {data_dir / 'item_features.pkl'} (å…± {len(item_features_data)} ä¸ªç‰©å“)")

    # --- 2. å¤„ç†ç”¨æˆ·ç‰¹å¾ ---
    print("\n--- æ­¥éª¤ 2: ä» seq.jsonl æå–ç”¨æˆ·ç‰¹å¾ -> user_features.pkl ---")
    user_feature_data = {}
    with open(user_seq_file, 'r', encoding='utf-8') as f:
        for line in tqdm(f, desc="æ‰«æç”¨æˆ·åºåˆ—æå–ç‰¹å¾"):
            try:
                sequence = json.loads(line)
                if not sequence: continue
                
                current_user_id = -1
                temp_user_features = {}

                for record in sequence:
                    user_id, item_id, user_feat, _, _, _ = record
                    current_user_id = user_id
                    
                    # å¦‚æœæ˜¯ç”¨æˆ·ç‰¹å¾è®°å½• (item_id is null)
                    if item_id is None and user_feat:
                        temp_user_features.update(user_feat)
                
                # åœ¨å¤„ç†å®Œæ•´ä¸ªåºåˆ—åï¼Œä¸ºè¯¥ç”¨æˆ·å¤„ç†ç‰¹å¾
                if current_user_id != -1:
                    processed_feats = {}
                    # å¤„ç†ç¨€ç–ç‰¹å¾
                    for key in USER_SPARSE_KEYS:
                        processed_feats[key] = temp_user_features.get(key, 0) # ç¼ºå¤±å€¼ä¸º0
                    
                    # å¤„ç†æ•°ç»„ç‰¹å¾ (Top-K & Padding)
                    for key in USER_ARRAY_KEYS:
                        vals = temp_user_features.get(key, [])
                        if not isinstance(vals, list): vals = [vals]
                        
                        top_k_vals = vals[:MAX_ARRAY_LENGTH_K]
                        padded_vals = top_k_vals + [0] * (MAX_ARRAY_LENGTH_K - len(top_k_vals))
                        processed_feats[key] = padded_vals
                    
                    user_feature_data[current_user_id] = processed_feats

            except (json.JSONDecodeError, IndexError):
                continue

    with open(data_dir / 'user_features.pkl', 'wb') as f:
        pickle.dump(user_feature_data, f)
    print(f"  - âœ… å·²ä¿å­˜: {data_dir / 'user_features.pkl'} (å…± {len(user_feature_data)} ä¸ªç”¨æˆ·)")
    print("\nğŸ‰ æ•°æ®é‡ç»„å®Œæ¯•ï¼")


if __name__ == '__main__':
    current_data_dir = Path(os.environ.get('TRAIN_DATA_PATH', 'data'))
    restructure_provided_data(current_data_dir)